{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple binary classification problem utilizing convolutional neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries. \n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,floatX=float32,optimizer=fast_compile'\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# \"\"\"\n",
    "# os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu3,floatX=float32,optimizer=fast_compile'\n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "# In case you want to select a graphic card (i the above code i set the 3rd graphic card.) \n",
    "# \"\"\"\n",
    "\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.api.layers import Convolution2D, MaxPooling2D\n",
    "from keras.api.optimizers import SGD\n",
    "from keras.api.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import numpy as np\n",
    "import keras \n",
    "import keras.api.backend as K\n",
    "from keras.api.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras import callbacks\n",
    "import glob\n",
    "from PIL import Image\n",
    "from keras.src.utils import plot_model\n",
    "import h5py\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is good to know the pid of the running code in case you need to stop  or monitor. \n",
    "# print (os.getpid())\n",
    "import keras.api\n",
    "\n",
    "\n",
    "file_open = lambda x,y: glob.glob(os.path.join(x,y))\n",
    "\n",
    "# learning rate schedule. It is helpful when the learning rate can be dynamically set up. We will be using the callback functionality that keras provides. \n",
    "def step_decay(epoch):\n",
    "  initial_lrate = 0.01\n",
    "  drop = 0.3\n",
    "  epochs_drop = 30.0\n",
    "  # This function doesn't actually affect the learning rate too much until a higher number of epochs is reached (around 30)\n",
    "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "  #print(\"Learning rate:\", lrate)\n",
    "  return lrate\n",
    "\n",
    "# The following function will be used to give a number of the parameters in our model. Useful when we need to get an estimate of what size of dataset we have to use.  \n",
    "def size(model): \n",
    "  return sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
    "\n",
    "def createmodel(img_rows, img_cols, optimizer, loss):\n",
    "  # This is a Sequential model. Graph models can be used in order to create more complex networks. \n",
    "  # Teaching Points:\n",
    "  # 1. Here we utilize the adam optimization algorithm. In order to use the SGD algorithm one could replace the {adam=keras.optimizers.Adadelta(lr=0)} line with  {sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)} make sure you import the correct optimizer from keras. \n",
    "  # 2. This is a binary classification problem so make sure that the correct activation loss function combination is used. For such a problem the sigmoid activation function with the binary cross entropy loss is a good option\n",
    "  # 3. Since this is a binary problem use   model.add(Dense(1)) NOT 2...\n",
    "  # 4. For multi class model this code can be easily modified by selecting the softmax as activation function and the categorical cross entropy as loss \n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Convolution2D(16, 3, 3, padding='same',input_shape=(img_rows, img_cols, 1)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(16, 5, 5, padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "  model.add(Convolution2D(32, 3, 3, padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(64, 5, 5, padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(64, 3, 3, padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "  model.add(Convolution2D(128, 3, 3, padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, kernel_initializer='he_normal'))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5)) \n",
    "  model.add(Dense(32, kernel_initializer='he_normal'))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5)) \n",
    "  model.add(Dense(1))\n",
    "\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  # learning schedule callback\n",
    "  \n",
    "  # Original code had the variable named \"adam\", but the selected optimizer was adadelta (they are similar optimizers but different slightly)\n",
    "  model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "  \n",
    "  # print(model.summary())\n",
    "  return model\n",
    "\n",
    "def shuffle(X, y):\n",
    "  perm = np.random.permutation(len(y))\n",
    "  X = X[perm]\n",
    "  y = y[perm]\n",
    "  print(\"shuffle() new shape for x: \", np.shape(X))\n",
    "  return X, y\n",
    "\n",
    "def read_data(image):\n",
    "  \"opens image and converts it to a m*n matrix\" \n",
    "  image = Image.open(image)\n",
    "  image = image.getdata()\n",
    "\n",
    "  image = np.array(image)\n",
    "  return image.reshape(-1)\n",
    "\n",
    "def createTrainTestValset(image_dir1, image_dir2):\n",
    "  Class1_images = file_open(image_dir1,\"*.jpg\")\n",
    "  Class2_images = file_open(image_dir2,\"*.jpg\")\n",
    "\n",
    "  # Read all the files, and create numpy arrays. \n",
    "  Class1_set = np.array([read_data(image) for image in Class1_images])\n",
    "  Class2_set = np.array([read_data(image) for image in Class2_images])\n",
    "  X = np.vstack((Class1_set, Class2_set))\n",
    "  \n",
    "  X = X / 255.0\n",
    "\n",
    "  yclass1 = np.zeros((np.shape(Class1_set)[0]))\n",
    "  yclass2 = np.ones((np.shape(Class2_set)[0]))\n",
    "  \n",
    "  y = np.concatenate((yclass1, yclass2))\n",
    "  \n",
    "  X,y = shuffle(X, y)\n",
    "\n",
    "  print(\"X shape:\", np.shape(X)) \n",
    "  print(\"X max:\", np.max(X))\n",
    "  print(\"Y shape:\", np.shape(y)) \n",
    "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  return X_train, y_train, X_val, y_val \n",
    "\n",
    "# Read the images; and split them in three different sets. \n",
    "def trainandpredict(optimizer, loss, lrate, checkpoint_file_name='Final', batch_size=64, nb_epoch=5):\n",
    "  \"\"\"\n",
    "  Train the model using some of the inputs, predict the remainder of the inputs using the fitted model and print the report.\n",
    "\n",
    "  :param optimizer: a keras.optimizers object that the model will recieve during compilation (could also be a string)\n",
    "  :param loss: a keras.losses object that the model will recieve during compilation (could also be a string)\n",
    "  :param lrate: a LearningRateScheduler that the model will consider during fitting\n",
    "  :param checkpoint_file_name: name of the file to save weights to. These values are used and altered during fitting, so \n",
    "    be sure to use the correct file for the correct model. Trying to use one weights file for a different model will most likely result\n",
    "    in an error. Have different weights files for different versions of the model.\n",
    "  :param batch_size: batch size used during fitting\n",
    "  :param nb_epoch: number of epochs run during fitting\n",
    "  \"\"\"\n",
    "  img_rows = 32\n",
    "  img_cols = 32\n",
    "  CurrentDir = os.getcwd()\n",
    "  image_dir1 = os.path.abspath(os.path.join(os.path.abspath(os.path.join(CurrentDir, os.pardir)), \"Data\", \"negative_images\"))\n",
    "  image_dir2 = os.path.abspath(os.path.join(os.path.abspath(os.path.join(CurrentDir, os.pardir)), \"Data\", \"positive_images\"))\n",
    "\n",
    "  modeleval = createmodel(img_rows, img_cols, optimizer, loss)\n",
    "\n",
    "  X_train,y_train, X_val, y_val = createTrainTestValset(image_dir1, image_dir2)\n",
    "\n",
    "  X_train = X_train.reshape(\n",
    "    -1,  # number of samples, -1 makes it so that this number is determined automatically\n",
    "    img_rows,  # first image dimension (vertical)\n",
    "    img_cols,  # second image dimension (horizontal)\n",
    "    1,   # 1 color channel, since images are only black and white\n",
    "  )\n",
    "  X_val = X_val.reshape(\n",
    "    -1,  # number of samples, -1 makes it so that this number is determined automatically\n",
    "    img_rows,  # first image dimension (vertical)\n",
    "    img_cols,  # second image dimension (horizontal)\n",
    "    1,   # 1 color channel, since images are only black and white\n",
    "  )\n",
    "\n",
    "  filepath = checkpoint_file_name + '.weights.h5'\n",
    "\n",
    "  # Callbacks\n",
    "  best_model = ModelCheckpoint(filepath, verbose=1, monitor='val_loss',save_best_only=True,save_weights_only=True)\n",
    "\n",
    "  # try:\n",
    "  #   modeleval.load_weights(filepath)\n",
    "  # except FileNotFoundError:\n",
    "  #   print(f\"Could not find file: {filepath}, assuming this is the first time with this model and will create a new file\")\n",
    "  # except ValueError as e:\n",
    "  #   print(e)\n",
    "  #   print(\"!!!!!!!ValueError detected, assuming this is a new model and a filepath for a different model's weights was inputted, consider a new weights file\")\n",
    "  #   sys.exit()\n",
    "\n",
    "  start = time.time()\n",
    "\n",
    "  modeleval.fit(X_train, y_train,batch_size=batch_size,epochs=nb_epoch,validation_split=0.1,callbacks=[best_model,lrate],shuffle=True, verbose=0)\n",
    "\n",
    "  print(\"Total time to fit:\", time.time() - start)\n",
    "\n",
    "  # Some evaluation Just the basic stuff... \n",
    "  #print (\"Dir:\", dir(modeleval))\n",
    "  Y_cv_pred = modeleval.predict(X_val, batch_size = 32)\n",
    "  roc = roc_auc_score(y_val, Y_cv_pred)\n",
    "  print(\"ROC:\", roc)\n",
    "  print (\"Y_cv_pred:\", Y_cv_pred)\n",
    "\n",
    "  Y_cv_pred[Y_cv_pred>=.5]=1\n",
    "  Y_cv_pred[Y_cv_pred<.5]=0\n",
    "   \n",
    "  target_names = ['class 0', 'class 1']\n",
    "  # Default notebook output size might not show all information from the result, make sure to expand it or change a setting when viewing\n",
    "  print(\"--------------------------\")\n",
    "  print(classification_report(y_val, Y_cv_pred, target_names=target_names,digits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.losses.losses.BinaryCrossentropy'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67268, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67268 to 0.67084, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.67084 to 0.67042, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67042 to 0.62970, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.62970 to 0.45022, saving model to Final.weights.h5\n",
      "Total time to fit: 5.388418197631836\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.8491834728336813\n",
      "Y_cv_pred: [[0.99137515]\n",
      " [0.9195901 ]\n",
      " [0.8303658 ]\n",
      " ...\n",
      " [0.5214859 ]\n",
      " [0.6021427 ]\n",
      " [0.7953685 ]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6355    0.5481    0.5886       509\n",
      "     class 1     0.8235    0.8702    0.8462      1233\n",
      "\n",
      "    accuracy                         0.7761      1742\n",
      "   macro avg     0.7295    0.7092    0.7174      1742\n",
      "weighted avg     0.7686    0.7761    0.7709      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.BinaryFocalCrossentropy'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.17591, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.17591\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.17591\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17591 to 0.17021, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.17021 to 0.14355, saving model to Final.weights.h5\n",
      "Total time to fit: 5.398228645324707\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.7688507208497377\n",
      "Y_cv_pred: [[0.44956535]\n",
      " [0.6197108 ]\n",
      " [0.5389066 ]\n",
      " ...\n",
      " [0.47617286]\n",
      " [0.49534073]\n",
      " [0.49557006]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.4448    0.9480    0.6055       519\n",
      "     class 1     0.9575    0.4980    0.6552      1223\n",
      "\n",
      "    accuracy                         0.6320      1742\n",
      "   macro avg     0.7012    0.7230    0.6304      1742\n",
      "weighted avg     0.8048    0.6320    0.6404      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.SquaredHinge'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.83018, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.83018\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.83018\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.83018\n",
      "\n",
      "Epoch 5: val_loss improved from 0.83018 to 0.69409, saving model to Final.weights.h5\n",
      "Total time to fit: 5.456628084182739\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.881700027283776\n",
      "Y_cv_pred: [[0.92503905]\n",
      " [0.1346681 ]\n",
      " [0.249829  ]\n",
      " ...\n",
      " [0.02648668]\n",
      " [0.90947074]\n",
      " [0.02685003]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.4005    0.9906    0.5704       534\n",
      "     class 1     0.9881    0.3444    0.5107      1208\n",
      "\n",
      "    accuracy                         0.5425      1742\n",
      "   macro avg     0.6943    0.6675    0.5405      1742\n",
      "weighted avg     0.8080    0.5425    0.5290      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.Dice'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.34236, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.34236 to 0.28341, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.28341 to 0.25018, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.25018 to 0.21051, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.21051 to 0.18297, saving model to Final.weights.h5\n",
      "Total time to fit: 5.43251895904541\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.7830731306491372\n",
      "Y_cv_pred: [[0.99744534]\n",
      " [0.9468018 ]\n",
      " [0.97603464]\n",
      " ...\n",
      " [0.9794686 ]\n",
      " [0.9506051 ]\n",
      " [0.9373517 ]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.9247    0.1638    0.2783       525\n",
      "     class 1     0.7338    0.9942    0.8444      1217\n",
      "\n",
      "    accuracy                         0.7440      1742\n",
      "   macro avg     0.8293    0.5790    0.5613      1742\n",
      "weighted avg     0.7913    0.7440    0.6738      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.Huber'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.12053, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.12053\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.12053\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.12053\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.12053\n",
      "Total time to fit: 8.511923789978027\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.8250028780843471\n",
      "Y_cv_pred: [[0.47138566]\n",
      " [0.37667933]\n",
      " [0.35730928]\n",
      " ...\n",
      " [0.427862  ]\n",
      " [0.34486455]\n",
      " [0.3007992 ]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.3254    1.0000    0.4910       506\n",
      "     class 1     1.0000    0.1513    0.2628      1236\n",
      "\n",
      "    accuracy                         0.3978      1742\n",
      "   macro avg     0.6627    0.5756    0.3769      1742\n",
      "weighted avg     0.8040    0.3978    0.3291      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.KLDivergence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.33406, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.33406 to 0.21949, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.21949 to 0.14329, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.14329 to 0.05884, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.05884 to 0.01582, saving model to Final.weights.h5\n",
      "Total time to fit: 5.541424989700317\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.6296103896103896\n",
      "Y_cv_pred: [[0.98695993]\n",
      " [0.97854203]\n",
      " [0.9744135 ]\n",
      " ...\n",
      " [0.99827933]\n",
      " [0.9913159 ]\n",
      " [0.9865164 ]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.0000    0.0000    0.0000       517\n",
      "     class 1     0.7032    1.0000    0.8257      1225\n",
      "\n",
      "    accuracy                         0.7032      1742\n",
      "   macro avg     0.3516    0.5000    0.4129      1742\n",
      "weighted avg     0.4945    0.7032    0.5807      1742\n",
      "\n",
      "<class 'keras.src.losses.losses.MeanAbsoluteError'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mpoth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle() new shape for x:  (8710, 1024)\n",
      "X shape: (8710, 1024)\n",
      "X max: 1.0\n",
      "Y shape: (8710,)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.47532, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.47532 to 0.45945, saving model to Final.weights.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.45945\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.45945\n",
      "\n",
      "Epoch 5: val_loss improved from 0.45945 to 0.38227, saving model to Final.weights.h5\n",
      "Total time to fit: 5.272068023681641\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "ROC: 0.8370978108931156\n",
      "Y_cv_pred: [[0.16887257]\n",
      " [0.04294595]\n",
      " [0.47750843]\n",
      " ...\n",
      " [0.95026284]\n",
      " [0.8212087 ]\n",
      " [0.12048066]]\n",
      "--------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.4857    0.9015    0.6313       528\n",
      "     class 1     0.9318    0.5848    0.7186      1214\n",
      "\n",
      "    accuracy                         0.6808      1742\n",
      "   macro avg     0.7087    0.7432    0.6750      1742\n",
      "weighted avg     0.7966    0.6808    0.6922      1742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Some of the optimizers provided by keras can take in variations of the\n",
    "    # keras.optimizers.schedules.LearningRateSchedule objects like\n",
    "    # keras.optimizers.schedules.ExponentialDecay for example, something to consider.\n",
    "    # This is NOT the same type of object as the lrate variable (keras.callbacks.LearningRateScheduler),\n",
    "    # which might be the source of the UserWarning when running, unsure of how to fix this.\n",
    "\n",
    "    optimizers = [keras.optimizers.Adadelta, keras.optimizers.Adafactor, keras.optimizers.Adagrad, keras.optimizers.Adam, keras.optimizers.Adamax,\n",
    "                  keras.optimizers.AdamW, keras.optimizers.Ftrl, keras.optimizers.Lion, keras.optimizers.Nadam, keras.optimizers.RMSprop, \n",
    "                  keras.optimizers.SGD]\n",
    "    \n",
    "    \n",
    "    \n",
    "    losses = [keras.losses.BinaryCrossentropy, keras.losses.BinaryFocalCrossentropy, keras.losses.SquaredHinge, keras.losses.Dice, keras.losses.Huber, keras.losses.KLDivergence, keras.losses.MeanAbsoluteError]\n",
    "\n",
    "    for opti in optimizers: \n",
    "        for loss in losses: \n",
    "            print(opti)\n",
    "            print(loss)\n",
    "            trainandpredict(optimizer=opti(learning_rate=0.0), \n",
    "                            loss=loss,\n",
    "                            lrate=LearningRateScheduler(step_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

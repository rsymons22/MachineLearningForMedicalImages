{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple binary classification problem utilizing convolutional neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries. \n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,floatX=float32,optimizer=fast_compile'\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# \"\"\"\n",
    "# os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu3,floatX=float32,optimizer=fast_compile'\n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "# In case you want to select a graphic card (i the above code i set the 3rd graphic card.) \n",
    "# \"\"\"\n",
    "\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.api.layers import Convolution2D, MaxPooling2D\n",
    "from keras.api.optimizers import SGD\n",
    "from keras.api.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import numpy as np\n",
    "import keras \n",
    "import keras.api.backend as K\n",
    "from keras.api.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras import callbacks\n",
    "import glob\n",
    "from PIL import Image\n",
    "from keras.src.utils import plot_model\n",
    "import h5py\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is good to know the pid of the running code in case you need to stop  or monitor. \n",
    "# print (os.getpid())\n",
    "import keras.api\n",
    "\n",
    "file_open = lambda x,y: glob.glob(os.path.join(x,y))\n",
    "\n",
    "# learning rate schedule. It is helpful when the learning rate can be dynamically set up. We will be using the callback functionality that keras provides. \n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.3\n",
    "    epochs_drop = 30.0\n",
    "    # This function doesn't actually affect the learning rate too much until a higher number of epochs is reached (around 30)\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    #print(\"Learning rate:\", lrate)\n",
    "    return lrate\n",
    "\n",
    "# The following function will be used to give a number of the parameters in our model. Useful when we need to get an estimate of what size of dataset we have to use.  \n",
    "def size(model): \n",
    "    return sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
    "\n",
    "def createmodel(img_rows, img_cols, optimizer, loss, activation):\n",
    "    # This is a Sequential model. Graph models can be used in order to create more complex networks. \n",
    "    # Teaching Points:\n",
    "    # 1. Here we utilize the adam optimization algorithm. In order to use the SGD algorithm one could replace the {adam=keras.optimizers.Adadelta(lr=0)} line with  {sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)} make sure you import the correct optimizer from keras. \n",
    "    # 2. This is a binary classification problem so make sure that the correct activation loss function combination is used. For such a problem the sigmoid activation function with the binary cross entropy loss is a good option\n",
    "    # 3. Since this is a binary problem use   model.add(Dense(1)) NOT 2...\n",
    "    # 4. For multi class model this code can be easily modified by selecting the softmax as activation function and the categorical cross entropy as loss \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, 3, 3, padding='same',input_shape=(img_rows, img_cols, 1)))\n",
    "    model.add(activation)\n",
    "    model.add(Convolution2D(16, 5, 5, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(activation)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Convolution2D(32, 3, 3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(activation)\n",
    "    model.add(Convolution2D(64, 5, 5, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(activation)\n",
    "    model.add(Convolution2D(64, 3, 3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(activation)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Convolution2D(128, 3, 3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(activation)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, kernel_initializer='he_normal'))\n",
    "    model.add(activation)\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(32, kernel_initializer='he_normal'))\n",
    "    model.add(activation)\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # learning schedule callback\n",
    "    \n",
    "    # Original code had the variable named \"adam\", but the selected optimizer was adadelta (they are similar optimizers but different slightly)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # print(model.summary())\n",
    "    return model\n",
    "\n",
    "def shuffle(X, y):\n",
    "    perm = np.random.permutation(len(y))\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    #print(\"shuffle() new shape for x: \", np.shape(X))\n",
    "    return X, y\n",
    "\n",
    "def read_data(image):\n",
    "    \"opens image and converts it to a m*n matrix\" \n",
    "    image = Image.open(image)\n",
    "    image = image.getdata()\n",
    "\n",
    "    image = np.array(image)\n",
    "    return image.reshape(-1)\n",
    "\n",
    "def createTrainTestValset(image_dir1, image_dir2):\n",
    "    Class1_images = file_open(image_dir1,\"*.jpg\")\n",
    "    Class2_images = file_open(image_dir2,\"*.jpg\")\n",
    "\n",
    "    # Read all the files, and create numpy arrays. \n",
    "    Class1_set = np.array([read_data(image) for image in Class1_images])\n",
    "    Class2_set = np.array([read_data(image) for image in Class2_images])\n",
    "    X = np.vstack((Class1_set, Class2_set))\n",
    "    \n",
    "    X = X / 255.0\n",
    "\n",
    "    yclass1 = np.zeros((np.shape(Class1_set)[0]))\n",
    "    yclass2 = np.ones((np.shape(Class2_set)[0]))\n",
    "    \n",
    "    y = np.concatenate((yclass1, yclass2))\n",
    "    \n",
    "    X,y = shuffle(X, y)\n",
    "\n",
    "    # print(\"X shape:\", np.shape(X)) \n",
    "    # print(\"X max:\", np.max(X))\n",
    "    # print(\"Y shape:\", np.shape(y)) \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, y_train, X_val, y_val \n",
    "\n",
    "# Read the images; and split them in three different sets. \n",
    "def trainandpredict(X_train, y_train, X_val, y_val, optimizer, loss, lrate, activation=Activation(keras.activations.relu), batch_size=64, nb_epoch=5):\n",
    "    \"\"\"\n",
    "    Train the model using some of the inputs, predict the remainder of the inputs using the fitted model and print the report.\n",
    "\n",
    "    :param optimizer: a keras.optimizers object that the model will recieve during compilation (could also be a string)\n",
    "    :param loss: a keras.losses object that the model will recieve during compilation (could also be a string)\n",
    "    :param lrate: a LearningRateScheduler that the model will consider during fitting\n",
    "    :param checkpoint_file_name: name of the file to save weights to. These values are used and altered during fitting, so \n",
    "      be sure to use the correct file for the correct model. Trying to use one weights file for a different model will most likely result\n",
    "      in an error. Have different weights files for different versions of the model.\n",
    "    :param batch_size: batch size used during fitting\n",
    "    :param nb_epoch: number of epochs run during fitting\n",
    "    \"\"\"\n",
    "    img_rows = 32\n",
    "    img_cols = 32\n",
    "    \n",
    "    modeleval = createmodel(img_rows, img_cols, optimizer, loss, activation)\n",
    "\n",
    "    X_train = X_train.reshape(\n",
    "      -1,  # number of samples, -1 makes it so that this number is determined automatically\n",
    "      img_rows,  # first image dimension (vertical)\n",
    "      img_cols,  # second image dimension (horizontal)\n",
    "      1,   # 1 color channel, since images are only black and white\n",
    "    )\n",
    "    X_val = X_val.reshape(\n",
    "      -1,  # number of samples, -1 makes it so that this number is determined automatically\n",
    "      img_rows,  # first image dimension (vertical)\n",
    "      img_cols,  # second image dimension (horizontal)\n",
    "      1,   # 1 color channel, since images are only black and white\n",
    "    )\n",
    "\n",
    "    # filepath = checkpoint_file_name + '.weights.h5'\n",
    "\n",
    "    # Callbacks (Don't need them for this project, but very useful for saving weights for later use)\n",
    "    # best_model = ModelCheckpoint(filepath, verbose=1, monitor='val_loss',save_best_only=True,save_weights_only=True)\n",
    "\n",
    "    # try:\n",
    "    #   modeleval.load_weights(filepath)\n",
    "    # except FileNotFoundError:\n",
    "    #   print(f\"Could not find file: {filepath}, assuming this is the first time with this model and will create a new file\")\n",
    "    # except ValueError as e:\n",
    "    #   print(e)\n",
    "    #   print(\"!!!!!!!ValueError detected, assuming this is a new model and a filepath for a different model's weights was inputted, consider a new weights file\")\n",
    "    #   sys.exit()\n",
    "\n",
    "    #modeleval.fit(X_train, y_train,batch_size=batch_size,epochs=nb_epoch,validation_split=0.1,callbacks=[best_model,lrate],shuffle=True, verbose=0)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    modeleval.fit(X_train, y_train,batch_size=batch_size,epochs=nb_epoch,validation_split=0.1,callbacks=[lrate],shuffle=True, verbose=0)\n",
    "    \n",
    "\n",
    "    print(\"Total time to fit:\", time.time() - start)\n",
    "\n",
    "    # Some evaluation Just the basic stuff... \n",
    "    #print (\"Dir:\", dir(modeleval))\n",
    "    Y_cv_pred = modeleval.predict(X_val, batch_size = 32)\n",
    "    roc = roc_auc_score(y_val, Y_cv_pred)\n",
    "    print(\"ROC:\", roc)\n",
    "    #print (\"Y_cv_pred:\", Y_cv_pred)\n",
    "\n",
    "    Y_cv_pred[Y_cv_pred>=.5]=1\n",
    "    Y_cv_pred[Y_cv_pred<.5]=0\n",
    "    \n",
    "    target_names = ['class 0', 'class 1']\n",
    "    # Default notebook output size might not show all information from the result, make sure to expand it or change a setting when viewing\n",
    "    print(classification_report(y_val, Y_cv_pred, target_names=target_names,digits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 32\n",
      "Total time to fit: 17.727851390838623\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9512054260553668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.9347    0.6497    0.7666       551\n",
      "     class 1     0.8580    0.9790    0.9145      1191\n",
      "\n",
      "    accuracy                         0.8749      1742\n",
      "   macro avg     0.8964    0.8144    0.8406      1742\n",
      "weighted avg     0.8823    0.8749    0.8677      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 64\n",
      "Total time to fit: 15.297008275985718\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9247235390656786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7056    0.8875    0.7862       551\n",
      "     class 1     0.9409    0.8287    0.8812      1191\n",
      "\n",
      "    accuracy                         0.8473      1742\n",
      "   macro avg     0.8233    0.8581    0.8337      1742\n",
      "weighted avg     0.8665    0.8473    0.8512      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 128\n",
      "Total time to fit: 10.193413496017456\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9382437244853644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6641    0.9220    0.7720       551\n",
      "     class 1     0.9560    0.7842    0.8616      1191\n",
      "\n",
      "    accuracy                         0.8278      1742\n",
      "   macro avg     0.8100    0.8531    0.8168      1742\n",
      "weighted avg     0.8636    0.8278    0.8333      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 32\n",
      "Total time to fit: 13.555471181869507\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9337819490095864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8098    0.8113    0.8105       551\n",
      "     class 1     0.9126    0.9118    0.9122      1191\n",
      "\n",
      "    accuracy                         0.8800      1742\n",
      "   macro avg     0.8612    0.8615    0.8614      1742\n",
      "weighted avg     0.8801    0.8800    0.8801      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 64\n",
      "Total time to fit: 9.688042402267456\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9337522343163563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6971    0.9274    0.7960       551\n",
      "     class 1     0.9604    0.8136    0.8809      1191\n",
      "\n",
      "    accuracy                         0.8496      1742\n",
      "   macro avg     0.8287    0.8705    0.8384      1742\n",
      "weighted avg     0.8771    0.8496    0.8540      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 128\n",
      "Total time to fit: 7.3103156089782715\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "ROC: 0.8255960843653476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8984    0.3049    0.4553       551\n",
      "     class 1     0.7537    0.9840    0.8536      1191\n",
      "\n",
      "    accuracy                         0.7692      1742\n",
      "   macro avg     0.8260    0.6445    0.6544      1742\n",
      "weighted avg     0.7995    0.7692    0.7276      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 32\n",
      "Total time to fit: 16.23284602165222\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9395976478153605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6851    0.9201    0.7854       551\n",
      "     class 1     0.9561    0.8044    0.8737      1191\n",
      "\n",
      "    accuracy                         0.8410      1742\n",
      "   macro avg     0.8206    0.8623    0.8296      1742\n",
      "weighted avg     0.8704    0.8410    0.8458      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 64\n",
      "Total time to fit: 11.217318296432495\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9283898750611438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8976    0.6044    0.7223       551\n",
      "     class 1     0.8410    0.9681    0.9001      1191\n",
      "\n",
      "    accuracy                         0.8530      1742\n",
      "   macro avg     0.8693    0.7862    0.8112      1742\n",
      "weighted avg     0.8589    0.8530    0.8439      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "batch_size: 128\n",
      "Total time to fit: 9.42294454574585\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "ROC: 0.9416807240023101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7754    0.8457    0.8090       551\n",
      "     class 1     0.9255    0.8866    0.9057      1191\n",
      "\n",
      "    accuracy                         0.8737      1742\n",
      "   macro avg     0.8504    0.8662    0.8573      1742\n",
      "weighted avg     0.8780    0.8737    0.8751      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "batch_size: 32\n",
      "Total time to fit: 17.81217050552368\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.8851245198029383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.4890    0.9655    0.6492       551\n",
      "     class 1     0.9709    0.5332    0.6883      1191\n",
      "\n",
      "    accuracy                         0.6699      1742\n",
      "   macro avg     0.7300    0.7493    0.6688      1742\n",
      "weighted avg     0.8185    0.6699    0.6760      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "batch_size: 64\n",
      "Total time to fit: 12.5641028881073\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "ROC: 0.9371435189206404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6150    0.9365    0.7424       551\n",
      "     class 1     0.9612    0.7288    0.8290      1191\n",
      "\n",
      "    accuracy                         0.7945      1742\n",
      "   macro avg     0.7881    0.8326    0.7857      1742\n",
      "weighted avg     0.8517    0.7945    0.8016      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "batch_size: 128\n",
      "Total time to fit: 10.31145167350769\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.8420001188587729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6545    0.3267    0.4358       551\n",
      "     class 1     0.7471    0.9202    0.8247      1191\n",
      "\n",
      "    accuracy                         0.7325      1742\n",
      "   macro avg     0.7008    0.6235    0.6303      1742\n",
      "weighted avg     0.7178    0.7325    0.7017      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "batch_size: 32\n",
      "Total time to fit: 16.911394119262695\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9451283903322104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8544    0.7241    0.7839       551\n",
      "     class 1     0.8808    0.9429    0.9108      1191\n",
      "\n",
      "    accuracy                         0.8737      1742\n",
      "   macro avg     0.8676    0.8335    0.8473      1742\n",
      "weighted avg     0.8724    0.8737    0.8706      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "batch_size: 64\n",
      "Total time to fit: 10.706545352935791\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9357492140844598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7508    0.8584    0.8010       551\n",
      "     class 1     0.9299    0.8682    0.8980      1191\n",
      "\n",
      "    accuracy                         0.8651      1742\n",
      "   macro avg     0.8403    0.8633    0.8495      1742\n",
      "weighted avg     0.8732    0.8651    0.8673      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "batch_size: 128\n",
      "Total time to fit: 8.2583646774292\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.7694840767340048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.5070    0.6552    0.5717       551\n",
      "     class 1     0.8155    0.7053    0.7564      1191\n",
      "\n",
      "    accuracy                         0.6894      1742\n",
      "   macro avg     0.6613    0.6802    0.6640      1742\n",
      "weighted avg     0.7180    0.6894    0.6980      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 5\n",
      "Total time to fit: 12.356569528579712\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.938368678579973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7912    0.8113    0.8011       551\n",
      "     class 1     0.9116    0.9009    0.9062      1191\n",
      "\n",
      "    accuracy                         0.8726      1742\n",
      "   macro avg     0.8514    0.8561    0.8537      1742\n",
      "weighted avg     0.8735    0.8726    0.8730      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 10\n",
      "Total time to fit: 17.749592304229736\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9452563920876629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8237    0.8566    0.8399       551\n",
      "     class 1     0.9324    0.9152    0.9237      1191\n",
      "\n",
      "    accuracy                         0.8967      1742\n",
      "   macro avg     0.8781    0.8859    0.8818      1742\n",
      "weighted avg     0.8980    0.8967    0.8972      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 15\n",
      "Total time to fit: 23.52542996406555\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9489791098087441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8982    0.7368    0.8096       551\n",
      "     class 1     0.8876    0.9614    0.9230      1191\n",
      "\n",
      "    accuracy                         0.8904      1742\n",
      "   macro avg     0.8929    0.8491    0.8663      1742\n",
      "weighted avg     0.8910    0.8904    0.8871      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 5\n",
      "Total time to fit: 9.112969636917114\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9060467114977578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8871    0.3993    0.5507       551\n",
      "     class 1     0.7784    0.9765    0.8663      1191\n",
      "\n",
      "    accuracy                         0.7939      1742\n",
      "   macro avg     0.8328    0.6879    0.7085      1742\n",
      "weighted avg     0.8128    0.7939    0.7665      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 10\n",
      "Total time to fit: 14.272709846496582\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9365042720585882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6549    0.9401    0.7720       551\n",
      "     class 1     0.9653    0.7708    0.8571      1191\n",
      "\n",
      "    accuracy                         0.8243      1742\n",
      "   macro avg     0.8101    0.8554    0.8146      1742\n",
      "weighted avg     0.8671    0.8243    0.8302      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.rmsprop.RMSprop'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 15\n",
      "Total time to fit: 19.644442796707153\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9477333784387139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6570    0.9456    0.7753       551\n",
      "     class 1     0.9684    0.7716    0.8589      1191\n",
      "\n",
      "    accuracy                         0.8266      1742\n",
      "   macro avg     0.8127    0.8586    0.8171      1742\n",
      "weighted avg     0.8699    0.8266    0.8324      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 5\n",
      "Total time to fit: 11.259377717971802\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9403100385376715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8945    0.6770    0.7707       551\n",
      "     class 1     0.8657    0.9631    0.9118      1191\n",
      "\n",
      "    accuracy                         0.8726      1742\n",
      "   macro avg     0.8801    0.8200    0.8412      1742\n",
      "weighted avg     0.8748    0.8726    0.8671      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 10\n",
      "Total time to fit: 18.54868483543396\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9531140236589912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8548    0.7695    0.8099       551\n",
      "     class 1     0.8981    0.9395    0.9183      1191\n",
      "\n",
      "    accuracy                         0.8858      1742\n",
      "   macro avg     0.8765    0.8545    0.8641      1742\n",
      "weighted avg     0.8844    0.8858    0.8841      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamw.AdamW'>\n",
      "loss: <class 'keras.src.losses.losses.Huber'>\n",
      "epochs: 15\n",
      "Total time to fit: 22.57310175895691\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "ROC: 0.9221916948194337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7881    0.7423    0.7645       551\n",
      "     class 1     0.8839    0.9076    0.8956      1191\n",
      "\n",
      "    accuracy                         0.8553      1742\n",
      "   macro avg     0.8360    0.8250    0.8300      1742\n",
      "weighted avg     0.8536    0.8553    0.8541      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "epochs: 5\n",
      "Total time to fit: 12.639354467391968\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.8857355758021823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.5750    0.9528    0.7172       551\n",
      "     class 1     0.9686    0.6742    0.7950      1191\n",
      "\n",
      "    accuracy                         0.7623      1742\n",
      "   macro avg     0.7718    0.8135    0.7561      1742\n",
      "weighted avg     0.8441    0.7623    0.7704      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "epochs: 10\n",
      "Total time to fit: 17.781935930252075\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9364539856546604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7174    0.9074    0.8013       551\n",
      "     class 1     0.9512    0.8346    0.8891      1191\n",
      "\n",
      "    accuracy                         0.8576      1742\n",
      "   macro avg     0.8343    0.8710    0.8452      1742\n",
      "weighted avg     0.8772    0.8576    0.8613      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.nadam.Nadam'>\n",
      "loss: <class 'keras.src.losses.losses.SquaredHinge'>\n",
      "epochs: 15\n",
      "Total time to fit: 24.460565090179443\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "ROC: 0.8893729590196285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.7199    0.6298    0.6718       551\n",
      "     class 1     0.8381    0.8866    0.8617      1191\n",
      "\n",
      "    accuracy                         0.8054      1742\n",
      "   macro avg     0.7790    0.7582    0.7668      1742\n",
      "weighted avg     0.8007    0.8054    0.8016      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "epochs: 5\n",
      "Total time to fit: 11.488708734512329\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "ROC: 0.9483284342185263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.6671    0.9419    0.7810       551\n",
      "     class 1     0.9668    0.7825    0.8650      1191\n",
      "\n",
      "    accuracy                         0.8330      1742\n",
      "   macro avg     0.8170    0.8622    0.8230      1742\n",
      "weighted avg     0.8720    0.8330    0.8384      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "epochs: 10\n",
      "Total time to fit: 18.686073541641235\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9423298757621056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8311    0.7949    0.8126       551\n",
      "     class 1     0.9070    0.9253    0.9160      1191\n",
      "\n",
      "    accuracy                         0.8840      1742\n",
      "   macro avg     0.8691    0.8601    0.8643      1742\n",
      "weighted avg     0.8830    0.8840    0.8833      1742\n",
      "\n",
      "optimizer: <class 'keras.src.optimizers.adamax.Adamax'>\n",
      "loss: <class 'keras.src.losses.losses.BinaryCrossentropy'>\n",
      "epochs: 15\n",
      "Total time to fit: 21.16871166229248\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "ROC: 0.9520686759894611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0     0.8768    0.7623    0.8155       551\n",
      "     class 1     0.8963    0.9505    0.9226      1191\n",
      "\n",
      "    accuracy                         0.8909      1742\n",
      "   macro avg     0.8866    0.8564    0.8691      1742\n",
      "weighted avg     0.8901    0.8909    0.8887      1742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    CurrentDir = os.getcwd()\n",
    "    image_dir1 = os.path.abspath(os.path.join(os.path.abspath(os.path.join(CurrentDir, os.pardir)), \"Data\", \"negative_images\"))\n",
    "    image_dir2 = os.path.abspath(os.path.join(os.path.abspath(os.path.join(CurrentDir, os.pardir)), \"Data\", \"positive_images\"))\n",
    "\n",
    "    X_train, y_train, X_val, y_val = createTrainTestValset(image_dir1, image_dir2)\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    optimizers = [keras.optimizers.Adadelta, keras.optimizers.Adafactor, keras.optimizers.Adagrad, keras.optimizers.Adam, keras.optimizers.Adamax,\n",
    "                  keras.optimizers.AdamW, keras.optimizers.Ftrl, keras.optimizers.Lion, keras.optimizers.Nadam, keras.optimizers.RMSprop, \n",
    "                  keras.optimizers.SGD]\n",
    "    \n",
    "    losses = [keras.losses.BinaryCrossentropy, keras.losses.BinaryFocalCrossentropy, keras.losses.SquaredHinge, keras.losses.Dice, \n",
    "              keras.losses.Huber, keras.losses.KLDivergence, keras.losses.MeanAbsoluteError]\n",
    "\n",
    "\n",
    "    for optimizer in optimizers: \n",
    "        for loss in losses: \n",
    "            print(optimizer)\n",
    "            print(loss)\n",
    "            trainandpredict(X_train, y_train, X_val, y_val,\n",
    "                            optimizer=optimizer(learning_rate=0.0), \n",
    "                            loss=loss,\n",
    "                            lrate=LearningRateScheduler(step_decay))\n",
    "            \n",
    "\n",
    "    # Step 2 \n",
    "\n",
    "    # Selected manually from looking at step 1 results\n",
    "    best_combinations = [(keras.optimizers.Nadam, keras.losses.Huber), (keras.optimizers.RMSprop, keras.losses.Huber),\n",
    "                         (keras.optimizers.AdamW, keras.losses.Huber), (keras.optimizers.Nadam, keras.losses.SquaredHinge),\n",
    "                         (keras.optimizers.Adamax, keras.losses.BinaryCrossentropy)]\n",
    "\n",
    "    # Testing activation functions\n",
    "    activations = [Activation(keras.activations.relu), Activation(keras.activations.selu), Activation(keras.activations.sigmoid)]\n",
    "\n",
    "    for comb in best_combinations:\n",
    "        for a in activations:\n",
    "            print(\"optimizer:\", comb[0])\n",
    "            print(\"loss:\", comb[1])\n",
    "            print(\"act:\", a.activation)\n",
    "            trainandpredict(X_train, y_train, X_val, y_val,\n",
    "                    optimizer=comb[0](learning_rate=0.0), \n",
    "                    loss=comb[1],\n",
    "                    lrate=LearningRateScheduler(step_decay),\n",
    "                    activation=a)\n",
    "            \n",
    "    # Testing batch sizes\n",
    "    batch_sizes = [32, 64, 128]\n",
    "    for comb in best_combinations:\n",
    "        for b in batch_sizes:\n",
    "            print(\"optimizer:\", comb[0])\n",
    "            print(\"loss:\", comb[1])\n",
    "            print(\"batch_size:\", b)\n",
    "            trainandpredict(X_train, y_train, X_val, y_val,\n",
    "                    optimizer=comb[0](learning_rate=0.0), \n",
    "                    loss=comb[1],\n",
    "                    lrate=LearningRateScheduler(step_decay),\n",
    "                    batch_size=b)\n",
    "            \n",
    "    # Testing epochs\n",
    "    epochs = [5, 10, 15]\n",
    "    for comb in best_combinations:\n",
    "        for e in epochs:\n",
    "            print(\"optimizer:\", comb[0])\n",
    "            print(\"loss:\", comb[1])\n",
    "            print(\"epochs:\", e)\n",
    "            trainandpredict(X_train, y_train, X_val, y_val,\n",
    "                    optimizer=comb[0](learning_rate=0.0), \n",
    "                    loss=comb[1],\n",
    "                    lrate=LearningRateScheduler(step_decay),\n",
    "                    nb_epoch=e)\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
